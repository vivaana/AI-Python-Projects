{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "RQ7PSbOt6CHG",
        "outputId": "fb996b66-41fe-4a96-b866-7cea6ac05eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-vision in /usr/local/lib/python3.11/dist-packages (3.10.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (4.25.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (4.9.1)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-vision)\n",
            "  Using cached protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2025.6.15)\n",
            "Using cached protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.8\n",
            "    Uninstalling protobuf-4.25.8:\n",
            "      Successfully uninstalled protobuf-4.25.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.15 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "bigframes 2.7.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-5.29.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ce288b51134541baa5674fb2521b2660"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install google-cloud-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QSPO146q8Jrn",
        "outputId": "c2970a7b-c00a-4635-a875-9184f93ee1b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.73.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.14.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12.0)\n",
            "  Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.14.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.15.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "orbax-checkpoint 0.11.15 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "bigframes 2.7.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-4.25.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "5fb7d5707805499781570cf906d5e023"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow==2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62ONaV_f5xg8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_dictionary(file_path):\n",
        "  responses = {}\n",
        "\n",
        "  try:\n",
        "    file = open(file_path, \"r\")\n",
        "    lines = file.readlines()\n",
        "    file.close()\n",
        "    for line in lines:\n",
        "      key, value = line.split(\":\")\n",
        "      responses[key] = value\n",
        "    return responses\n",
        "  except:\n",
        "    print(\"Error: Make sure your file is called\", file_path)\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def can_handle(self,  text):\n",
        "        pass\n",
        "\n",
        "    def get_response(self, text):\n",
        "        pass\n",
        "\n",
        "\n",
        "class ConditionalAgent(Agent):\n",
        "    def __init__(self, file_path):\n",
        "      self.conditional_responses = read_dictionary(file_path)\n",
        "#Landmark Mode function------------------------------------------------------------------------------------------------------\n",
        "    def landmark():\n",
        "      import io\n",
        "      from google.cloud import vision\n",
        "\n",
        "      client = vision.ImageAnnotatorClient.from_service_account_json('creds.json')\n",
        "      landy_pic = input(\"🤖 Please enter the filepath for your image: \")\n",
        "      try:\n",
        "        print(f\"{landy_pic} was accepted!\")\n",
        "\n",
        "        with io.open(landy_pic, \"rb\") as image_file:\n",
        "          content = image_file.read()\n",
        "\n",
        "        image = vision.Image(content=content)\n",
        "        response = client.landmark_detection(image = image)\n",
        "        landmarks = response.landmark_annotations\n",
        "\n",
        "        print(\"⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯\")\n",
        "\n",
        "        if len(landmarks) == 0:\n",
        "          print(\"🤖 No landmarks found\")\n",
        "          print(\"⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯\")\n",
        "          print()\n",
        "\n",
        "        else:\n",
        "          for landmark in landmarks:\n",
        "            print(f\"🤖 {landmark.description}\")\n",
        "            print(\"⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯\")\n",
        "            print()\n",
        "\n",
        "      except:\n",
        "        print(\"Error: Make sure your filepath is valid.\")\n",
        "        ConditionalAgent.landmark()\n",
        "\n",
        "        print(\"\\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "#Number Mode function------------------------------------------------------------------------------------------------------\n",
        "    def number_recognition():\n",
        "      from keras.models import load_model  # TensorFlow is required for Keras to work\n",
        "      from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
        "      import numpy as np\n",
        "\n",
        "      model = load_model(\"my_model_nummy.h5\")\n",
        "      image_prediction = input(\"🤖 Please enter the filepath for your image: \")\n",
        "\n",
        "      try:\n",
        "        def image_predictor(image_name):\n",
        "          img = np.invert(Image.open(image_name).convert(\"L\"))\n",
        "          img = img.reshape(1, 28, 28, 1)\n",
        "          img = img.astype(\"float32\")\n",
        "          img /= 255\n",
        "\n",
        "          preddy = model.predict(img)\n",
        "          print(np.argmax(preddy))\n",
        "\n",
        "        image_predictor(image_prediction)\n",
        "\n",
        "      except:\n",
        "        print(\"Please enter a valid filepath: \")\n",
        "        ConditionalAgent.number_recognition()\n",
        "      print(f\"\")\n",
        "      print(\"\\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "#Emotion Mode function------------------------------------------------------------------------------------------------------\n",
        "    def emotion_recognition():\n",
        "      import io\n",
        "      from google.cloud import vision\n",
        "\n",
        "      client = vision.ImageAnnotatorClient.from_service_account_json('creds.json')\n",
        "\n",
        "      image_to_see = input(\"Please enter the filepath to analyse: \")\n",
        "\n",
        "      with io.open(image_to_see, \"rb\") as image_file:\n",
        "        content = image_file.read()\n",
        "\n",
        "      image = vision.Image(content=content)\n",
        "\n",
        "      response = client.face_detection(image = image)\n",
        "      faces = response.face_annotations\n",
        "\n",
        "      print(f\"🤖 There are {len(faces)} people in this picture!\")\n",
        "      print(\"---------------------------------------------\")\n",
        "\n",
        "      likelihood_name = (\"unknown\", \"very unlikely\", \"unlikely\", \"possibly\", \"likely\", \"very likely\")\n",
        "      count = 0\n",
        "\n",
        "      for face in faces:\n",
        "        #print(f'\\tPosition {face.bounding_poly}')\n",
        "        count += 1\n",
        "        print(f\"Person {count}\")\n",
        "        print(f\"\\tThis person is {likelihood_name[face.joy_likelihood]} to be happy\")\n",
        "        print(f\"\\tThis person is {likelihood_name[face.sorrow_likelihood]} to be sad\")\n",
        "        print(f\"\\tThis person is {likelihood_name[face.anger_likelihood]} to be angry\")\n",
        "        print(f\"\\tThis person is {likelihood_name[face.surprise_likelihood]} to be surprised\")\n",
        "      print(f\"\")\n",
        "      print(\"\\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "#Research Mode function------------------------------------------------------------------------------------------------------\n",
        "    def Research_Mode():\n",
        "      from google.cloud import language\n",
        "      client = language.LanguageServiceClient.from_service_account_json(\"creds.json\")\n",
        "      print(\"Enter a question, or sentence and I will do a wikipedia Search!\")\n",
        "      print(\"To get a wikipedia link on a specific word, try and capitalise it.\")\n",
        "      text = input(\"Enter your sentence/question: \")\n",
        "\n",
        "      document = language.Document(content=text, type=language.Document.Type.PLAIN_TEXT)\n",
        "      response = client.analyze_entities(document=document, encoding_type= \"UTF32\")\n",
        "      entities = response.entities\n",
        "\n",
        "      for entity in entities:\n",
        "        print(entity.name)\n",
        "        print(language.Entity.Type(entity.type).name)\n",
        "        print(entity.metadata[\"wikipedia_url\"])\n",
        "\n",
        "    def Image_analyser():\n",
        "      import io\n",
        "      from google.cloud import vision\n",
        "\n",
        "      client = vision.ImageAnnotatorClient.from_service_account_json('creds.json')\n",
        "      try:\n",
        "        image_to_check = input(\"Please enter the filepath for your image so I can guess it.\")\n",
        "\n",
        "        with io.open(image_to_check, \"rb\") as image_file:\n",
        "          content = image_file.read()\n",
        "\n",
        "        image = vision.Image(content=content)\n",
        "\n",
        "        response = client.label_detection(image = image)\n",
        "        labels = response.label_annotations\n",
        "\n",
        "        for label in labels:\n",
        "          print(label.description, label.score)\n",
        "      except:\n",
        "        print(\"Sorry, please enter a valid filepath.\")\n",
        "        ConditionalAgent.Image_analyser()\n",
        "#Animal Mode function------------------------------------------------------------------------------------------------------\n",
        "    def Animals():\n",
        "\n",
        "      animal_image = input(\"Please input the filepath below to see whether it is a cat, dog, monkey or a squirrel: \")\n",
        "\n",
        "      try:\n",
        "        from keras.models import load_model  # TensorFlow is required for Keras to work\n",
        "        from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
        "        import numpy as np\n",
        "\n",
        "        np.set_printoptions(suppress=True)\n",
        "\n",
        "        model = load_model(\"latest_teachable_model.h5\", compile=False)\n",
        "\n",
        "        class_names = open(\"labels.txt\", \"r\").readlines()\n",
        "\n",
        "        data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "        image = Image.open(animal_image).convert(\"RGB\")\n",
        "\n",
        "        size = (224, 224)\n",
        "        image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
        "\n",
        "        image_array = np.asarray(image)\n",
        "\n",
        "        normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
        "\n",
        "        data[0] = normalized_image_array\n",
        "\n",
        "        prediction = model.predict(data)\n",
        "        index = np.argmax(prediction)\n",
        "        class_name = class_names[index]\n",
        "        confidence_score = prediction[0][index]\n",
        "\n",
        "        print(\"Class:\", class_name[2:], end=\"\")\n",
        "        print(\"Confidence Score:\", confidence_score)\n",
        "\n",
        "        pred = model.predict(data)\n",
        "        print(pred)\n",
        "        print(class_names)\n",
        "\n",
        "      except:\n",
        "        print(\"Sorry, please enter a valid filepath: \")\n",
        "        ConditionalAgent.Animals()\n",
        "#Can_handle function------------------------------------------------------------------------------------------------------\n",
        "    def can_handle(self, text):\n",
        "      not_sure = []\n",
        "      if text in self.conditional_responses:\n",
        "        #print(f\"DEBUG: Response for {text} is {self.conditional_responses[text]}\")\n",
        "        result = self.conditional_responses[text] is not None\n",
        "        if result:\n",
        "          print(f\"\")\n",
        "        else:\n",
        "          print(\"_____________________________________________\")\n",
        "          #print(f\"ConditionalAgent cannot handle text {text}\")\n",
        "        return result\n",
        "\n",
        "        return self.conditional_responses[text]\n",
        "      else:\n",
        "        #print(f\"ConditionalAgent cannot handle text '{text}'\")\n",
        "        not_sure.append(text)\n",
        "#Get_Response function------------------------------------------------------------------------------------------------------\n",
        "    def get_response(self, text):\n",
        "      if text in self.conditional_responses:\n",
        "        #print(f\"DEBUG: Response for {text} is {self.conditional_responses[text]}\")\n",
        "        return self.conditional_responses[text]\n",
        "      elif text == \"landmark\":\n",
        "        ConditionalAgent.landmark()\n",
        "      elif text == \"number\":\n",
        "        ConditionalAgent.number_recognition()\n",
        "      elif text == \"research\":\n",
        "          ConditionalAgent.Research_Mode()\n",
        "      elif text == \"emotion\":\n",
        "          ConditionalAgent.emotion_recognition()\n",
        "      elif text == \"animal\":\n",
        "          ConditionalAgent.Animal()\n",
        "\n",
        "      else:\n",
        "        print(\"_____________________________________________\")\n",
        "        print(f\"ConditionalAgent cannot handle text '{text}'\")\n",
        "\n",
        "class VivBot:\n",
        "    def __init__(self):\n",
        "        self.agents = []\n",
        "\n",
        "    def add_agent(self, agent):\n",
        "        self.agents.append(agent)\n",
        "\n",
        "    def get_response(self, text):\n",
        "        for agent in self.agents:\n",
        "            if agent.can_handle(text):\n",
        "                return agent.get_response(text)\n",
        "\n",
        "        return \"I'm sorry I don't understand \" + text + \" \\n\"\n",
        "\n",
        "print(\"Welcome to chat GuptaV!\")\n",
        "print(\"If you want to know the list of commands, then enter commands.\")\n",
        "print(\"For the best experience, please upload all necessary files, like responses.txt and creds.json, please.\")\n",
        "print()\n",
        "chatbot = VivBot()\n",
        "simple_agent = ConditionalAgent(\"responses.txt\")\n",
        "chatbot.add_agent(simple_agent)\n",
        "\n",
        "while True:\n",
        "  loser_input = input(\"🙂 Input: \")\n",
        "  user_input = loser_input.lower()\n",
        "  if user_input == \"landmark\":\n",
        "    ConditionalAgent.landmark()\n",
        "  if user_input == \"commands\":\n",
        "    print(\"Talk normally:\\t\\t\\t type anything\")\n",
        "    print(\"Landmark detection:\\t\\t 'landmark'\")\n",
        "    print(\"Entity recognition & research:\\t 'research'\")\n",
        "    print(\"Emotion detection:\\t\\t 'emotion'\")\n",
        "    print(\"Animal detection:\\t\\t 'animal'\")\n",
        "    print(\"Image detection:\\t\\t 'image'\")\n",
        "    print(\"Quit/exit conversation:\\t\\t 'goodbye'\\n\")\n",
        "  #if user_input == \"number\":\n",
        "    #ConditionalAgent.number_recognition()\n",
        "  if user_input == \"research\":\n",
        "    ConditionalAgent.Research_Mode()\n",
        "  if user_input == \"emotion\":\n",
        "    ConditionalAgent.emotion_recognition()\n",
        "  if user_input == \"animal\":\n",
        "    ConditionalAgent.Animals()\n",
        "  if user_input == \"image\":\n",
        "    ConditionalAgent.Image_analyser()\n",
        "  if user_input == \"goodbye\":\n",
        "    print(\"🤖. Goodbye! Have a great day!\")\n",
        "    break\n",
        "  response = chatbot.get_response(user_input)\n",
        "  print(\"🤖 Output:\", response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
